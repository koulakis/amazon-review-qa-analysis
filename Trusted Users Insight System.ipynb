{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'Musical_Instruments'\n",
    "\n",
    "reviews_filepath = './data/raw_data/reviews_{0}_5.json.gz'.format(dataset)\n",
    "metadata_filepath = './data/metadata/meta_{0}.json.gz'.format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# %load modules/scripts/Load\\ datasets.py\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "# reviews_filepath = '../../data/raw_data/reviews_Musical_Instruments_5.json.gz'\n",
    "# metadata_filepath = '../../data/metadata/meta_Musical_Instruments.json.gz'\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "all_reviews = (spark\n",
    "    .read\n",
    "    .json(reviews_filepath)).cache()\n",
    "\n",
    "all_metadata = (spark\n",
    "    .read\n",
    "    .json(metadata_filepath)).cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always predicting 5 stars accuracy: 0.506515993803\n"
     ]
    }
   ],
   "source": [
    "# %load modules/scripts/Summarize\\ reviews.py\n",
    "\n",
    "\n",
    "# # Summarize the reviews\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "# all_reviews = (spark\n",
    "#     .read\n",
    "#     .json('../../data/raw_data/reviews_Musical_Instruments_5.json.gz'))\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "from pyspark.sql.functions import col, expr, udf, trim\n",
    "from pyspark.sql.types import IntegerType\n",
    "import re\n",
    "\n",
    "remove_punctuation = udf(lambda line: re.sub('[^A-Za-z\\s]', '', line))\n",
    "make_binary = udf(lambda rating: 0 if rating in [1, 2] else 1, IntegerType())\n",
    "\n",
    "reviews = (all_reviews\n",
    "    .na.fill({ 'reviewerName': 'Unknown' })\n",
    "    .filter(col('overall').isin([1, 2, 5]))\n",
    "    .withColumn('label', make_binary(col('overall')))\n",
    "    .select(col('label').cast('int'), remove_punctuation('reviewText').alias('review'))\n",
    "    .filter(trim(col('review')) != ''))\n",
    "\n",
    "\n",
    "# ## Splitting data and balancing skewness\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "train, test = reviews.randomSplit([.8, .2], seed=5436L)\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "def multiply_dataset(dataset, n):\n",
    "    return dataset if n <= 1 else dataset.union(multiply_dataset(dataset, n - 1))\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "reviews_good = train.filter('label == 1')\n",
    "reviews_bad = train.filter('label == 0')\n",
    "\n",
    "reviews_bad_multiplied = multiply_dataset(reviews_bad, reviews_good.count() / reviews_bad.count())\n",
    "\n",
    "\n",
    "train_reviews = reviews_bad_multiplied.union(reviews_good)\n",
    "\n",
    "\n",
    "# ## Benchmark: predict by distribution\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "accuracy = reviews_good.count() / float(train_reviews.count())\n",
    "print('Always predicting 5 stars accuracy: {0}'.format(accuracy))\n",
    "\n",
    "\n",
    "# ## Learning pipeline\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StopWordsRemover\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='review', outputCol='words')\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    tokenizer, \n",
    "    StopWordsRemover(inputCol='words', outputCol='filtered_words'),\n",
    "    HashingTF(inputCol='filtered_words', outputCol='rawFeatures', numFeatures=120000),\n",
    "    IDF(inputCol='rawFeatures', outputCol='features'),\n",
    "    LogisticRegression(regParam=.3, elasticNetParam=.01)\n",
    "])\n",
    "\n",
    "\n",
    "# ## Testing the model accuracy\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "model = pipeline.fit(train_reviews)\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "prediction = model.transform(test)\n",
    "BinaryClassificationEvaluator().evaluate(prediction)\n",
    "\n",
    "\n",
    "# ## Using model to extract the most predictive words\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "from pyspark.sql.functions import explode\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "words = (tokenizer\n",
    "    .transform(reviews)\n",
    "    .select(explode(col('words')).alias('review')))\n",
    "\n",
    "predictors = (model\n",
    "    .transform(words)\n",
    "    .select(col('review').alias('word'), 'probability'))\n",
    "\n",
    "first = udf(lambda x: x[0].item(), FloatType())\n",
    "second = udf(lambda x: x[1].item(), FloatType())\n",
    "\n",
    "predictive_words = (predictors\n",
    "   .select(\n",
    "       'word', \n",
    "       second(col('probability')).alias('positive'), \n",
    "       first(col('probability')).alias('negative'))\n",
    "   .groupBy('word')\n",
    "   .agg(\n",
    "       F.max('positive').alias('positive'),\n",
    "       F.max('negative').alias('negative')))\n",
    "\n",
    "positive_predictive_words = (predictive_words\n",
    "    .select(col('word').alias('positive_word'), col('positive').alias('pos_prob'))\n",
    "    .sort('pos_prob', ascending=False))\n",
    "\n",
    "negative_predictive_words = (predictive_words\n",
    "    .select(col('word').alias('negative_word'), col('negative').alias('neg_prob'))\n",
    "    .sort('neg_prob', ascending=False))\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "pd.concat(\n",
    "    [ positive_predictive_words.limit(100).toPandas(),\n",
    "      negative_predictive_words.limit(100).toPandas() ],\n",
    "    axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load modules/scripts/User\\ trustedness.py\n",
    "\n",
    "\n",
    "# # User trustedness\n",
    "\n",
    "# ## Loading data\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "# all_reviews = (spark\n",
    "#     .read\n",
    "#     .json('../../data/raw_data/reviews_Musical_Instruments_5.json.gz'))\n",
    "\n",
    "\n",
    "# ## Extracting ranking components\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "reviews = all_reviews\n",
    "reviews_per_reviewer = reviews.groupBy('reviewerID').count()\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "from pyspark.sql.functions import col, udf, avg\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "helpfulness_ratio = udf(\n",
    "    lambda (useful, out_of): useful / float(out_of + 1), \n",
    "    returnType=DoubleType())\n",
    "\n",
    "helpfulness = (reviews\n",
    "  .select('reviewerID', helpfulness_ratio(col('helpful')).alias('helpfulness'))\n",
    "  .groupBy('reviewerID')\n",
    "  .agg(avg(col('helpfulness')).alias('helpfulness')))\n",
    "\n",
    "\n",
    "# ## Computing rankings & visualizing the good and bad reviews from the most trusted users\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "reviewers_trustedness = (helpfulness\n",
    "    .join(reviews_per_reviewer, 'reviewerID')\n",
    "    .select('reviewerID', (col('helpfulness') * col('count')).alias('trustedness')))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "reviewers_trustedness.limit(10).toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# %load modules/scripts/Recommender\\ system.py\n",
    "\n",
    "\n",
    "# ## Loading and indexing the data for training\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "# all_reviews = (spark\n",
    "#     .read\n",
    "#     .json('../../data/raw_data/reviews_Musical_Instruments_5.json.gz'))\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "from pyspark.sql.functions import col, expr, udf, trim\n",
    "from pyspark.sql.types import IntegerType\n",
    "import re\n",
    "\n",
    "remove_punctuation = udf(lambda line: re.sub('[^A-Za-z\\s]', '', line))\n",
    "make_binary = udf(lambda rating: 0 if rating in [1, 2] else 1, IntegerType())\n",
    "\n",
    "reviews = all_reviews.withColumn('label', make_binary(col('overall')))\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexing_pipeline = Pipeline(stages=[\n",
    "    StringIndexer(inputCol=\"reviewerID\", outputCol=\"reviewerIndex\"),\n",
    "    StringIndexer(inputCol=\"asin\", outputCol=\"asinIndex\")\n",
    "])\n",
    "\n",
    "indexer = indexing_pipeline.fit(reviews)\n",
    "indexed_reviews = indexer.transform(reviews)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "train, _, test = [ chunk.cache() for chunk in indexed_reviews.randomSplit([.6, .2, .2], seed=1800009193L) ]\n",
    "\n",
    "\n",
    "# ## Balancing data\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "def multiply_dataset(dataset, n):\n",
    "    return dataset if n <= 1 else dataset.union(multiply_dataset(dataset, n - 1))\n",
    "\n",
    "reviews_good = train.filter('label == 1')\n",
    "reviews_bad = train.filter('label == 0')\n",
    "\n",
    "reviews_bad_multiplied = multiply_dataset(reviews_bad, reviews_good.count() / reviews_bad.count())\n",
    "\n",
    "train_reviews = reviews_bad_multiplied.union(reviews_good)\n",
    "\n",
    "\n",
    "# ## Evaluator\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='label')\n",
    "\n",
    "\n",
    "# ## Benchmark: predict by distribution\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "average_rating = (train_reviews\n",
    "    .groupBy()\n",
    "    .avg('label')\n",
    "    .collect()[0][0])\n",
    "\n",
    "average_rating_prediction = test.withColumn('prediction', lit(average_rating))\n",
    "\n",
    "average_rating_evaluation = evaluator.evaluate(average_rating_prediction)\n",
    "\n",
    "print('The RMSE of always predicting {0} stars is {1}'.format(average_rating, average_rating_evaluation))\n",
    "\n",
    "\n",
    "# ## Recommender system\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "        maxIter=15,\n",
    "        regParam=0.1,\n",
    "        userCol='reviewerIndex',\n",
    "        itemCol='asinIndex',\n",
    "        ratingCol='label',\n",
    "        rank=24,        \n",
    "        seed=1800009193L)\n",
    "\n",
    "\n",
    "# ## Evaluating the model\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "recommender_system = als.fit(train_reviews)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "predictions = recommender_system.transform(test)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "evaluation = evaluator.evaluate(predictions.filter(col('prediction') != float('nan')))\n",
    "\n",
    "print('The RMSE of the recommender system is {0}'.format(evaluation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B003VWJ2K8</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0002E1G5C</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0002F7K7Y</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B003VWKPHC</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0002H0A3S</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B0002CZVXM</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B0006NDF8A</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B0009G1E0K</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B0002E2KPC</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B0002GLDQM</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  count\n",
       "0  B003VWJ2K8  163  \n",
       "1  B0002E1G5C  143  \n",
       "2  B0002F7K7Y  116  \n",
       "3  B003VWKPHC  114  \n",
       "4  B0002H0A3S  93   \n",
       "5  B0002CZVXM  74   \n",
       "6  B0006NDF8A  71   \n",
       "7  B0009G1E0K  69   \n",
       "8  B0002E2KPC  68   \n",
       "9  B0002GLDQM  67   "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewed_products = (all_metadata\n",
    "    .join(all_reviews, 'asin')\n",
    "    .filter('''\n",
    "        categories is not null \n",
    "        and related is not null'''))\n",
    "\n",
    "(reviewed_products\n",
    "     .groupBy('asin')\n",
    "     .count()\n",
    "     .sort('count', ascending=False)\n",
    "     .limit(10)\n",
    "     .toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_product = 'B003VWJ2K8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>neg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broke</td>\n",
       "      <td>0.402869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fulfills</td>\n",
       "      <td>0.402353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>something</td>\n",
       "      <td>0.382664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crazy</td>\n",
       "      <td>0.382145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stay</td>\n",
       "      <td>0.376246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>brand</td>\n",
       "      <td>0.375234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ball</td>\n",
       "      <td>0.375227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>decent</td>\n",
       "      <td>0.370760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>work</td>\n",
       "      <td>0.368903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fragile</td>\n",
       "      <td>0.367034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cheap</td>\n",
       "      <td>0.366470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gotta</td>\n",
       "      <td>0.365964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tried</td>\n",
       "      <td>0.364644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spent</td>\n",
       "      <td>0.362841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>industry</td>\n",
       "      <td>0.359923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>read</td>\n",
       "      <td>0.357828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>might</td>\n",
       "      <td>0.357725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>better</td>\n",
       "      <td>0.357025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>parts</td>\n",
       "      <td>0.355253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>first</td>\n",
       "      <td>0.354878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>two</td>\n",
       "      <td>0.354382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>thing</td>\n",
       "      <td>0.353870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pitches</td>\n",
       "      <td>0.353564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>get</td>\n",
       "      <td>0.353106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>item</td>\n",
       "      <td>0.352552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>low</td>\n",
       "      <td>0.352446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pitch</td>\n",
       "      <td>0.351354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dead</td>\n",
       "      <td>0.350706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fine</td>\n",
       "      <td>0.350065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>short</td>\n",
       "      <td>0.349991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bought</td>\n",
       "      <td>0.349324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>buy</td>\n",
       "      <td>0.349082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>worth</td>\n",
       "      <td>0.348727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>standard</td>\n",
       "      <td>0.347136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>second</td>\n",
       "      <td>0.346989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>another</td>\n",
       "      <td>0.346432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>gets</td>\n",
       "      <td>0.345977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gave</td>\n",
       "      <td>0.345879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>head</td>\n",
       "      <td>0.345754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>want</td>\n",
       "      <td>0.345435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>convenient</td>\n",
       "      <td>0.345223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>improved</td>\n",
       "      <td>0.343853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>much</td>\n",
       "      <td>0.343702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>from</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>stars</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>like</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>for</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>every</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>class</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>third</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>after</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tuned</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>goodby</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>new</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>amazon</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>what</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>appears</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>hit</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>precise</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>will</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>because</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>just</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>gadget</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>with</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>you</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>be</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>own</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>headstock</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>retired</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>is</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>lil</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>upgrade</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>them</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>really</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>it</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>snark</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>eats</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>in</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>too</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>i</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>by</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>out</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>the</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>than</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>more</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>fast</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>on</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>but</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>use</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>miracle</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>drasticly</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>gizmo</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>arm</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>expect</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>bread</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>have</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>break</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>done</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>one</td>\n",
       "      <td>0.342895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  neg_prob\n",
       "0        broke  0.402869\n",
       "1     fulfills  0.402353\n",
       "2    something  0.382664\n",
       "3        crazy  0.382145\n",
       "4         stay  0.376246\n",
       "5        brand  0.375234\n",
       "6         ball  0.375227\n",
       "7       decent  0.370760\n",
       "8         work  0.368903\n",
       "9      fragile  0.367034\n",
       "10       cheap  0.366470\n",
       "11       gotta  0.365964\n",
       "12       tried  0.364644\n",
       "13       spent  0.362841\n",
       "14    industry  0.359923\n",
       "15        read  0.357828\n",
       "16       might  0.357725\n",
       "17      better  0.357025\n",
       "18       parts  0.355253\n",
       "19       first  0.354878\n",
       "20         two  0.354382\n",
       "21       thing  0.353870\n",
       "22     pitches  0.353564\n",
       "23         get  0.353106\n",
       "24        item  0.352552\n",
       "25         low  0.352446\n",
       "26       pitch  0.351354\n",
       "27        dead  0.350706\n",
       "28        fine  0.350065\n",
       "29       short  0.349991\n",
       "30      bought  0.349324\n",
       "31         buy  0.349082\n",
       "32       worth  0.348727\n",
       "33    standard  0.347136\n",
       "34      second  0.346989\n",
       "35     another  0.346432\n",
       "36        gets  0.345977\n",
       "37        gave  0.345879\n",
       "38        head  0.345754\n",
       "39        want  0.345435\n",
       "40  convenient  0.345223\n",
       "41    improved  0.343853\n",
       "42        much  0.343702\n",
       "43        from  0.342895\n",
       "44       stars  0.342895\n",
       "45        like  0.342895\n",
       "46         for  0.342895\n",
       "47       every  0.342895\n",
       "48       class  0.342895\n",
       "49       third  0.342895\n",
       "50       after  0.342895\n",
       "51       sweet  0.342895\n",
       "52       tuned  0.342895\n",
       "53      goodby  0.342895\n",
       "54         new  0.342895\n",
       "55      amazon  0.342895\n",
       "56        what  0.342895\n",
       "57     appears  0.342895\n",
       "58         hit  0.342895\n",
       "59     precise  0.342895\n",
       "60        will  0.342895\n",
       "61     because  0.342895\n",
       "62        just  0.342895\n",
       "63      gadget  0.342895\n",
       "64        with  0.342895\n",
       "65         you  0.342895\n",
       "66          be  0.342895\n",
       "67         own  0.342895\n",
       "68   headstock  0.342895\n",
       "69     retired  0.342895\n",
       "70          is  0.342895\n",
       "71         lil  0.342895\n",
       "72     upgrade  0.342895\n",
       "73        them  0.342895\n",
       "74      really  0.342895\n",
       "75          it  0.342895\n",
       "76       snark  0.342895\n",
       "77        eats  0.342895\n",
       "78          in  0.342895\n",
       "79         too  0.342895\n",
       "80           i  0.342895\n",
       "81          by  0.342895\n",
       "82         out  0.342895\n",
       "83         the  0.342895\n",
       "84        than  0.342895\n",
       "85        more  0.342895\n",
       "86        fast  0.342895\n",
       "87          on  0.342895\n",
       "88         but  0.342895\n",
       "89         use  0.342895\n",
       "90     miracle  0.342895\n",
       "91   drasticly  0.342895\n",
       "92       gizmo  0.342895\n",
       "93         arm  0.342895\n",
       "94      expect  0.342895\n",
       "95       bread  0.342895\n",
       "96        have  0.342895\n",
       "97       break  0.342895\n",
       "98        done  0.342895\n",
       "99         one  0.342895"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "product_words_per_reviewer = (\n",
    "    Tokenizer(inputCol='summary', outputCol='words')\n",
    "        .transform(all_reviews.filter(col('asin') == selected_product))\n",
    "    .select('reviewerID', 'words'))\n",
    "\n",
    "word_ranks = (product_words_per_reviewer\n",
    "    .select(explode(col('words')).alias('word'))\n",
    "    .distinct()\n",
    "    .join(negative_predictive_words, col('word') == negative_predictive_words.negative_word)\n",
    "    .select('word', 'neg_prob')\n",
    "    .sort('neg_prob', ascending=False))\n",
    "\n",
    "word_ranks.limit(100).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_negative_word = 'broke'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trusted users that used the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10VG94SAKVSC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A15WZCSME5X74S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID\n",
       "0  A10VG94SAKVSC0\n",
       "1  A15WZCSME5X74S"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, lit\n",
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "is_elemen_of = udf(lambda word, words: word in words, BooleanType())\n",
    "\n",
    "users_that_used_the_word = (product_words_per_reviewer\n",
    "    .filter(is_elemen_of(lit(selected_negative_word), col('words')))\n",
    "    .select('reviewerID'))\n",
    "\n",
    "users_that_used_the_word.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested products in the same category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product category: Tuners\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "product_category = (reviewed_products\n",
    "    .filter(col('asin') == selected_product)\n",
    "    .select('categories')\n",
    "    .take(1)[0][0][0][-1])\n",
    "\n",
    "print('Product category: {0}'.format(product_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000EEEYCW</td>\n",
       "      <td>Korg GA-40 Large Display Guitar and Bass Tuner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B006X735PQ</td>\n",
       "      <td>Snark SN-2 All Instrument Tuner with Tap Tempo Metronome - Includes ChromaCast Pick Sampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000EE8YPK</td>\n",
       "      <td>Korg CA-40 Large Display Auto Chromatic Tuner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B001XJBWXG</td>\n",
       "      <td>Korg AW2G Clip-on Chromatic Guitar Tuner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004GYM7IE</td>\n",
       "      <td>Snark SN4 All Instrument Tuner Metronome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B0073XCXHA</td>\n",
       "      <td>Snark SN-8 Super Tight Tuner with ChromaCast Guitar Pick Sampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B000M23OQ8</td>\n",
       "      <td>Qwik Tune GP1 Guitar Professor Guitar Tuner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B0073XCYO2</td>\n",
       "      <td>Snark SN-5 Tuner for Guitar, Bass, Violin with ChromaCast Guitar Pick Sampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B00CDA0IUC</td>\n",
       "      <td>Guitar Tuner - Clip on - Electronic - Tune Acoustic - Electric Musical Instruments - Bass - Ukulele - Chromatic - Digital - Beginners - Pro - Good - Standard - Mini - Headstock - Easy Tuning - Accurate - Pitch - Turn 360 Degrees - Solid - Free Lesson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B000WGJ71U</td>\n",
       "      <td>Korg CM-100L Clip On Contact Microphone For Tuners</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  \\\n",
       "0  B000EEEYCW   \n",
       "1  B006X735PQ   \n",
       "2  B000EE8YPK   \n",
       "3  B001XJBWXG   \n",
       "4  B004GYM7IE   \n",
       "5  B0073XCXHA   \n",
       "6  B000M23OQ8   \n",
       "7  B0073XCYO2   \n",
       "8  B00CDA0IUC   \n",
       "9  B000WGJ71U   \n",
       "\n",
       "                                                                                                                                                                                                                                                        title  \n",
       "0  Korg GA-40 Large Display Guitar and Bass Tuner                                                                                                                                                                                                              \n",
       "1  Snark SN-2 All Instrument Tuner with Tap Tempo Metronome - Includes ChromaCast Pick Sampler                                                                                                                                                                 \n",
       "2  Korg CA-40 Large Display Auto Chromatic Tuner                                                                                                                                                                                                               \n",
       "3  Korg AW2G Clip-on Chromatic Guitar Tuner                                                                                                                                                                                                                    \n",
       "4  Snark SN4 All Instrument Tuner Metronome                                                                                                                                                                                                                    \n",
       "5  Snark SN-8 Super Tight Tuner with ChromaCast Guitar Pick Sampler                                                                                                                                                                                            \n",
       "6  Qwik Tune GP1 Guitar Professor Guitar Tuner                                                                                                                                                                                                                 \n",
       "7  Snark SN-5 Tuner for Guitar, Bass, Violin with ChromaCast Guitar Pick Sampler                                                                                                                                                                               \n",
       "8  Guitar Tuner - Clip on - Electronic - Tune Acoustic - Electric Musical Instruments - Bass - Ukulele - Chromatic - Digital - Beginners - Pro - Good - Standard - Mini - Headstock - Easy Tuning - Accurate - Pitch - Turn 360 Degrees - Solid - Free Lesson  \n",
       "9  Korg CM-100L Clip On Contact Microphone For Tuners                                                                                                                                                                                                          "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "last_element = udf(lambda categories: categories[0][-1])\n",
    "\n",
    "products_in_same_category = (reviewed_products\n",
    "    .limit(100000)\n",
    "    .filter(last_element(col('categories')) == product_category)\n",
    "    .select('asin', 'title')\n",
    "    .distinct())\n",
    "\n",
    "products_in_same_category.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E3BSKS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B002KDHBRU</td>\n",
       "      <td>0.614865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004GYM7IE</td>\n",
       "      <td>0.598390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0073XCYO2</td>\n",
       "      <td>0.576774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0073XCXHA</td>\n",
       "      <td>0.572057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B001XJBWXG</td>\n",
       "      <td>0.571303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00CDA0IUC</td>\n",
       "      <td>0.568401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B006X735PQ</td>\n",
       "      <td>0.548423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B000PR3JEM</td>\n",
       "      <td>0.546630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B003WZ6VVM</td>\n",
       "      <td>0.531225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B003VWKPHC</td>\n",
       "      <td>0.527869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B002Q0WSO8</td>\n",
       "      <td>0.527639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B004GYOZ6G</td>\n",
       "      <td>0.527022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B000WGJ71U</td>\n",
       "      <td>0.518465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B002PMHAVS</td>\n",
       "      <td>0.517469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B000SJJCX4</td>\n",
       "      <td>0.508969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B003VWJ2K8</td>\n",
       "      <td>0.467207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B002HPMTZU</td>\n",
       "      <td>0.457486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B005FKF1PY</td>\n",
       "      <td>0.439721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B000EEEYCW</td>\n",
       "      <td>0.321216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B00FXKIG5I</td>\n",
       "      <td>0.307139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B000BBRZ3S</td>\n",
       "      <td>0.286373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>B000M23OQ8</td>\n",
       "      <td>0.225143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B0033PSLSM</td>\n",
       "      <td>0.197229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B000EE8YPK</td>\n",
       "      <td>0.156864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          asin  prediction\n",
       "0   B001E3BSKS NaN        \n",
       "1   B002KDHBRU  0.614865  \n",
       "2   B004GYM7IE  0.598390  \n",
       "3   B0073XCYO2  0.576774  \n",
       "4   B0073XCXHA  0.572057  \n",
       "5   B001XJBWXG  0.571303  \n",
       "6   B00CDA0IUC  0.568401  \n",
       "7   B006X735PQ  0.548423  \n",
       "8   B000PR3JEM  0.546630  \n",
       "9   B003WZ6VVM  0.531225  \n",
       "10  B003VWKPHC  0.527869  \n",
       "11  B002Q0WSO8  0.527639  \n",
       "12  B004GYOZ6G  0.527022  \n",
       "13  B000WGJ71U  0.518465  \n",
       "14  B002PMHAVS  0.517469  \n",
       "15  B000SJJCX4  0.508969  \n",
       "16  B003VWJ2K8  0.467207  \n",
       "17  B002HPMTZU  0.457486  \n",
       "18  B005FKF1PY  0.439721  \n",
       "19  B000EEEYCW  0.321216  \n",
       "20  B00FXKIG5I  0.307139  \n",
       "21  B000BBRZ3S  0.286373  \n",
       "22  B000M23OQ8  0.225143  \n",
       "23  B0033PSLSM  0.197229  \n",
       "24  B000EE8YPK  0.156864  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "indexed_products = indexer.transform(\n",
    "    products_in_same_category.crossJoin(users_that_used_the_word))\n",
    "\n",
    "alternative_products = (recommender_system\n",
    "    .transform(indexed_products)\n",
    "    .groupBy('asin')\n",
    "    .agg(avg(col('prediction')).alias('prediction'))\n",
    "    .sort('prediction', ascending=False))\n",
    "\n",
    "alternative_products.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = (all_reviews\n",
    "    .filter(col('overall').isin([1, 2, 5]))\n",
    "    .withColumn('label', make_binary(col('overall')))\n",
    "    .select(col('label').cast('int'), remove_punctuation('summary').alias('summary'))\n",
    "    .filter(trim(col('summary')) != ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_contributing_summaries(product, total_reviews, ranking_model):\n",
    "    reviews = total_reviews.filter(col('asin') == product).select('summary', 'overall')\n",
    "    \n",
    "    udf_max = udf(lambda p: max(p.tolist()), FloatType())\n",
    "    \n",
    "    summary_ranks = (ranking_model\n",
    "        .transform(reviews)\n",
    "        .select(\n",
    "            'summary', \n",
    "            second(col('probability')).alias('pos_prob')))\n",
    "    \n",
    "    pos_summaries = { row[0]: row[1] for row in summary_ranks.sort('pos_prob', ascending=False).take(10) }\n",
    "    neg_summaries = { row[0]: row[1] for row in summary_ranks.sort('pos_prob').take(10) }\n",
    "    \n",
    "    return pos_summaries, neg_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def present_product(product, total_reviews, ranking_model):\n",
    "    pos_summaries, neg_summaries = most_contributing_summaries(product, total_reviews, ranking_model)\n",
    "    \n",
    "    pos_wordcloud = WordCloud(background_color='white', max_words=20).fit_words(pos_summaries)\n",
    "    neg_wordcloud = WordCloud(background_color='white', max_words=20).fit_words(neg_summaries)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.set_title('Positive summaries')\n",
    "    ax.imshow(pos_wordcloud, interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    ax.set_title('Negative summaries')\n",
    "    ax.imshow(neg_wordcloud, interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "present_product(best_product, all_reviews, full_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
