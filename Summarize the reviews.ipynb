{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the reviews\n",
    "\n",
    "The idea in this solution is to provide a new feature to the customer which will reduce the need to go through several reviews in order to evaluate a product. In order to achieve that, we will attempt to extract the most predictive words or sentences from the ratings and present them in a nice format (e.g. wordcloud).\n",
    "\n",
    "Implementation steps:\n",
    "\n",
    "- Extract the product and extract all the reviews associated with the product\n",
    "- Group reviews 4 and 5, get a list of words, train against their rating and determine the most common words.\n",
    "- Rank and present the most common words\n",
    "- Similarly group reviews 1, 2 and 3 for negative reviews\n",
    "- Could consider clustering the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_reviews = (spark\n",
    "    .read\n",
    "    .json('./data/raw_data/reviews_Amazon_Instant_Video_5.json.gz',)\n",
    "    .na\n",
    "    .fill({ 'reviewerName': 'Unknown' }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, udf, trim\n",
    "from pyspark.sql.types import IntegerType\n",
    "import re\n",
    "\n",
    "remove_punctuation = udf(lambda line: re.sub('[^A-Za-z]', ' ', line))\n",
    "make_binary = udf(lambda rating: 0 if rating in [1, 2] else 1, IntegerType())\n",
    "\n",
    "reviews = (all_reviews\n",
    "    .filter(col('overall').isin([1, 2, 5]))\n",
    "    .withColumn('label', make_binary(col('overall')))\n",
    "    .select(col('label').cast('int'), remove_punctuation('summary').alias('summary'))\n",
    "    .filter(trim(col('summary')) != ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: predict by distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always predicting 5 stars accuracy: 0.852979645222\n"
     ]
    }
   ],
   "source": [
    "accuracy = reviews.filter('label == 1').count() / float(reviews.count())\n",
    "print('Always predicting 5 stars accuracy: {0}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting lists of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8997182875012932]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, PCA\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='summary', outputCol='words')\n",
    "hashing_tf = HashingTF(inputCol='words', outputCol='rawFeatures')\n",
    "log_regression = LogisticRegression()\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    tokenizer, \n",
    "    hashing_tf,\n",
    "    IDF(inputCol='rawFeatures', outputCol='features'),\n",
    "    log_regression\n",
    "])\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "    .addGrid(hashing_tf.numFeatures, [120000])\n",
    "    .addGrid(log_regression.regParam, [.3])\n",
    "    .addGrid(log_regression.elasticNetParam, [.01])\n",
    "    .build())\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=2)\n",
    "\n",
    "model = crossval.fit(reviews)\n",
    "model.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "words = (tokenizer\n",
    "    .transform(reviews)\n",
    "    .select(explode(col('words')).alias('summary')))\n",
    "\n",
    "predictors = model.transform(words).select('summary', 'probability')\n",
    "\n",
    "first = udf(lambda x: x[0].item(), FloatType())\n",
    "second = udf(lambda x: x[1].item(), FloatType())\n",
    "\n",
    "predictors_good = (predictors\n",
    "   .select('summary', second(col('probability')).alias('prob_good'))\n",
    "   .groupBy('summary')\n",
    "   .agg(pyspark.sql.functions.max('prob_good').alias('prob_good'))\n",
    "   .sort('prob_good', ascending=False))\n",
    "\n",
    "predictors_bad = (predictors\n",
    "   .select('summary', first(col('probability')).alias('prob_bad'))\n",
    "   .groupBy('summary')\n",
    "   .agg(pyspark.sql.functions.max('prob_bad').alias('prob_bad'))\n",
    "   .sort('prob_bad', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|      summary| prob_good|\n",
      "+-------------+----------+\n",
      "|    excellent| 0.8987591|\n",
      "|        great| 0.8983653|\n",
      "|      awesome| 0.8981597|\n",
      "|         best|0.89773893|\n",
      "|          fun|0.89716154|\n",
      "|       regime|0.89715546|\n",
      "|         love|0.89715546|\n",
      "|     breaking|0.89684784|\n",
      "|         five| 0.8967087|\n",
      "|       sexist|0.89591557|\n",
      "|      amazing|  0.895506|\n",
      "| americanized|  0.895506|\n",
      "|     favorite| 0.8954664|\n",
      "|       series| 0.8953605|\n",
      "|         wait|0.89534503|\n",
      "|    hilarious|0.89526236|\n",
      "|        loved| 0.8951537|\n",
      "|    fantastic| 0.8946325|\n",
      "|        keeps| 0.8940002|\n",
      "|    endearing| 0.8940002|\n",
      "|         show|0.89345884|\n",
      "|        rocks|  0.893363|\n",
      "|    wonderful|  0.893318|\n",
      "|         miss| 0.8927371|\n",
      "|        loves| 0.8926713|\n",
      "|    customers| 0.8926098|\n",
      "|    brilliant| 0.8926098|\n",
      "|         hang|0.89243275|\n",
      "|    justified|0.89243275|\n",
      "|    enjoyable|0.89234406|\n",
      "|  outstanding|  0.892175|\n",
      "| entertaining|0.89214385|\n",
      "|       always| 0.8918692|\n",
      "|       season|0.89142704|\n",
      "|      classic|  0.891205|\n",
      "|       hooked|0.89120495|\n",
      "|        smart| 0.8911705|\n",
      "|entertainment|0.89106065|\n",
      "|       flames| 0.8906066|\n",
      "|        still| 0.8905752|\n",
      "|       poirot|0.89042366|\n",
      "|         must| 0.8902579|\n",
      "|    continues|0.89018106|\n",
      "|          wow|0.88958627|\n",
      "|      enjoyed| 0.8890181|\n",
      "|          see| 0.8885347|\n",
      "|     gatoroid| 0.8885347|\n",
      "|  intelligent| 0.8884095|\n",
      "|          lie| 0.8881114|\n",
      "|        quote| 0.8879755|\n",
      "+-------------+----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictors_good.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|      summary|  prob_bad|\n",
      "+-------------+----------+\n",
      "|        kiosk|  0.385591|\n",
      "|          meh|0.38450035|\n",
      "|disappointing| 0.3837381|\n",
      "|       boring|0.38158318|\n",
      "|  unwatchable|0.38135895|\n",
      "|     mediocre|0.37024063|\n",
      "|        waste|0.36363545|\n",
      "|       sucked|0.36315715|\n",
      "|         skip|0.36098742|\n",
      "|   depressing|  0.355512|\n",
      "|      charges|0.35515267|\n",
      "|           eh|0.35515267|\n",
      "|         crap|  0.346826|\n",
      "|          yuk|0.34450716|\n",
      "|      stinker|0.34450716|\n",
      "|          ehh|0.34450716|\n",
      "|    worthless|0.34450716|\n",
      "|         yawn|0.34450716|\n",
      "|      garbage|0.34354392|\n",
      "|      protest|0.34224117|\n",
      "|       search|0.34196168|\n",
      "|         nope|0.33954385|\n",
      "|         mess|0.33739823|\n",
      "|         weak|0.33659312|\n",
      "|     tiresome|0.33552718|\n",
      "|         bore| 0.3343576|\n",
      "|     terrible|0.33435202|\n",
      "|      nowhere|0.33308926|\n",
      "|          ugh| 0.3330458|\n",
      "|   unbearable|0.33196622|\n",
      "|       wasted|0.33094722|\n",
      "|        falls|0.33044004|\n",
      "|       stupid|0.33038098|\n",
      "|          hum|0.32854858|\n",
      "|      weakest|0.32756776|\n",
      "|        bored|0.32746166|\n",
      "|       aweful|0.32521757|\n",
      "|        worst|0.32348457|\n",
      "|          log|0.32214835|\n",
      "|       stinks| 0.3221471|\n",
      "|         poor|0.32195392|\n",
      "|       rotten|0.32115832|\n",
      "|         melt| 0.3211223|\n",
      "|      failure| 0.3210916|\n",
      "|      pretend| 0.3205299|\n",
      "|  frustrating| 0.3198154|\n",
      "|        rails| 0.3191623|\n",
      "|         yuck|0.31855214|\n",
      "|dissapointing|0.31848553|\n",
      "|       sloppy|0.31848553|\n",
      "+-------------+----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictors_bad.show(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
