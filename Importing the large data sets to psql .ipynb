{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the large datasets to a postgresql server\n",
    "\n",
    "It is not possible to load the larger data sets in the memory of a local machine therefeore an alternative is to import them to a psql table and query them from there. By adding the right indices this can make the queries fast enough. After this import one can extract some basic statistics using sql and also export smaller portions of the data which can be handled by spark or pandas on a local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzipping the data and converting it to csv format\n",
    "\n",
    "Unfortunately psql does not support an import of record json files therefore we need to convert the data sets to csv. We use here the command line tool [json2csv](https://github.com/jehiah/json2csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: ./data/large-datasets/reviews_CDs_and_Vinyl_5.json: unknown suffix -- ignored\n",
      "rm: cannot remove 'reviews_CDs_and_Vinyl_5': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!gunzip ./data/large-datasets/reviews_CDs_and_Vinyl_5.json.gz ./data/large-datasets/reviews_CDs_and_Vinyl_5.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!json2csv -p -d '|' -k asin,helpful,overall,reviewText,reviewTime,reviewerID,reviewerName,summary,unixReviewTime -i ./data/large-datasets/reviews_CDs_and_Vinyl_5.json -o ./data/large-datasets/reviews_CDs_and_Vinyl_5.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data in psql\n",
    "\n",
    "To import the data in psql we create a table with the appropriate shape and import form the csv files generated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preparation to run psql transactions and queries in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "\n",
    "db_conf = { \n",
    "    'user': 'mariosk',\n",
    "    'database': 'amazon_reviews'\n",
    "}\n",
    "\n",
    "connection_factory = lambda: pg.connect(user=db_conf['user'], database=db_conf['database'])\n",
    "\n",
    "def transaction(*statements):\n",
    "    try:\n",
    "        connection = connection_factory()\n",
    "        cursor = connection.cursor()\n",
    "        for statement in statements:\n",
    "            cursor.execute(statement)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "    except pg.DatabaseError as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if connection is not None:\n",
    "            connection.close()\n",
    "    \n",
    "def query(statement):\n",
    "    try:\n",
    "        connection = connection_factory()\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(statement)\n",
    "        \n",
    "        header = [ description[0] for description in cursor.description ]\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        cursor.close()\n",
    "        return pd.DataFrame.from_records(rows, columns=header)\n",
    "    except (Exception, pg.DatabaseError) as error:\n",
    "        print(error)\n",
    "        return None\n",
    "    finally:\n",
    "        if connection is not None:\n",
    "            connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tables for with indices for the large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction(\n",
    "    'create table cds (asin text, helpful text, overall double precision, reviewText text, reviewTime text, reviewerID text, reviewerName text, summary text, unixReviewTime int);',\n",
    "    'create index asin ON cds (asin);',\n",
    "    'create index overall ON cds (overall);',\n",
    "    'create index reviewerID ON cds (reviewerID);',\n",
    "    'create index unixReviewTime ON cds (unixReviewTime);')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the datasets to psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPY 1097592\r\n"
     ]
    }
   ],
   "source": [
    "!psql -U mariosk -d amazon_reviews -c \"\\copy cds from './data/large-datasets/reviews_CDs_and_Vinyl_5.csv' with (format csv, delimiter '|', header true);\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reviews_per_product = query('''\n",
    "    with distinct_products as (select count(distinct asin) as products from cds),\n",
    "         reviews_count as (select cast(count(*) as double precision) as reviews from cds)\n",
    "    select reviews / products as reviews_per_product\n",
    "    from distinct_products cross join reviews_count\n",
    "''').rename(index={ 0: 'row'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reviews_per_reviewer = query('''\n",
    "    with distinct_reviewers as (select count(distinct reviewerID) as reviewers from cds),\n",
    "         reviews_count as (select cast(count(*) as double precision) as reviews from cds)\n",
    "    select reviews / reviewers as reviews_per_reviewer\n",
    "    from distinct_reviewers cross join reviews_count\n",
    "''').rename(index={ 0: 'row'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages_per_rating = (query('''\n",
    "    with rating_counts as (select count(overall) as rating_count from cds group by overall),\n",
    "         reviews_count as (select cast(count(*) as double precision) as reviews from cds)\n",
    "    select rating_count / reviews as row\n",
    "    from rating_counts cross join reviews_count\n",
    "    ''')\n",
    " .transpose()\n",
    " .rename(columns=lambda x: str(x + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.concat([percentages_per_rating, average_reviews_per_product, average_reviews_per_reviewer], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>reviews_per_product</th>\n",
       "      <th>reviews_per_reviewer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row</th>\n",
       "      <td>0.224424</td>\n",
       "      <td>0.04243</td>\n",
       "      <td>0.042088</td>\n",
       "      <td>0.09277</td>\n",
       "      <td>0.598288</td>\n",
       "      <td>17.031982</td>\n",
       "      <td>14.58439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1        2         3        4         5  reviews_per_product  \\\n",
       "row  0.224424  0.04243  0.042088  0.09277  0.598288            17.031982   \n",
       "\n",
       "     reviews_per_reviewer  \n",
       "row              14.58439  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
