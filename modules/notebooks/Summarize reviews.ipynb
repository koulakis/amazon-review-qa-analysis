{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_reviews = (spark\n",
    "#     .read\n",
    "#     .json('../../data/raw_data/reviews_Musical_Instruments_5.json.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, udf, trim\n",
    "from pyspark.sql.types import IntegerType\n",
    "import re\n",
    "\n",
    "remove_punctuation = udf(lambda line: re.sub('[^A-Za-z\\s]', '', line))\n",
    "make_binary = udf(lambda rating: 0 if rating in [1, 2] else 1, IntegerType())\n",
    "\n",
    "reviews = (all_reviews\n",
    "    .na.fill({ 'reviewerName': 'Unknown' })\n",
    "    .filter(col('overall').isin([1, 2, 5]))\n",
    "    .withColumn('label', make_binary(col('overall')))\n",
    "    .select(col('label').cast('int'), remove_punctuation('summary').alias('summary'))\n",
    "    .filter(trim(col('summary')) != ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data and balancing skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = reviews.randomSplit([.8, .2], seed=5436L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiply_dataset(dataset, n):\n",
    "    return dataset if n <= 1 else dataset.union(multiply_dataset(dataset, n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_good = train.filter('label == 1')\n",
    "reviews_bad = train.filter('label == 0')\n",
    "\n",
    "reviews_bad_multiplied = multiply_dataset(reviews_bad, reviews_good.count() / reviews_bad.count())\n",
    "\n",
    "\n",
    "train_reviews = reviews_bad_multiplied.union(reviews_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: predict by distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always predicting 5 stars accuracy: 0.506650874636\n"
     ]
    }
   ],
   "source": [
    "accuracy = reviews_good.count() / float(train_reviews.count())\n",
    "print('Always predicting 5 stars accuracy: {0}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='summary', outputCol='words')\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    tokenizer, \n",
    "    HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=120000),\n",
    "    IDF(inputCol='rawFeatures', outputCol='features'),\n",
    "    LogisticRegression(regParam=.3, elasticNetParam=.01)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8499835214632943"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "prediction = model.transform(test)\n",
    "BinaryClassificationEvaluator().evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using model to extract the most predictive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "words = (tokenizer\n",
    "    .transform(reviews)\n",
    "    .select(explode(col('words')).alias('summary')))\n",
    "\n",
    "predictors = (model\n",
    "    .transform(words)\n",
    "    .select(col('summary').alias('word'), 'probability'))\n",
    "\n",
    "first = udf(lambda x: x[0].item(), FloatType())\n",
    "second = udf(lambda x: x[1].item(), FloatType())\n",
    "\n",
    "predictive_words = (predictors\n",
    "   .select(\n",
    "       'word', \n",
    "       second(col('probability')).alias('positive'), \n",
    "       first(col('probability')).alias('negative'))\n",
    "   .groupBy('word')\n",
    "   .agg(\n",
    "       F.max('positive').alias('positive'),\n",
    "       F.max('negative').alias('negative')))\n",
    "\n",
    "positive_predictive_words = (predictive_words\n",
    "    .select(col('word').alias('positive_word'), col('positive').alias('pos_prob'))\n",
    "    .sort('pos_prob', ascending=False))\n",
    "\n",
    "negative_predictive_words = (predictive_words\n",
    "    .select(col('word').alias('negative_word'), col('negative').alias('neg_prob'))\n",
    "    .sort('neg_prob', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.concat([\n",
    "    positive_predictive_words.limit(10).toPandas(),\n",
    "    negative_predictive_words.limit(10).toPandas() ],\n",
    "    axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
